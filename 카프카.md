## 아파치 카프카 TOOL
<em><u>모두 JAVA기반이다.</u></em> <br>
`프로듀서` : 데이터 넣는역할 <br>
`토픽` : 프로듀서가 넣은 데이터가 토픽에 들어간다<br>
`컨슈머` : 토픽에 있는 데이터를 가져가는 역할<br>
`스트림즈` : 토픽에 있는 데이터를 StateFull, StateLess 하게 어떠한 처리를 해서 다시 토픽에 넣는역할 <br>
`커넥트` : 
1. 데이터 파이프라인을 연결하는 가장 핵심적인 tool 이다
2. 일반적인 프로듀서, 컨슈머와의 차이점은 클러스터로 운영이 가능하고, 템플릿형태로써 반복적으로 여러번 생성이 가능하다
```
프로듀서, 컨슈머를 개별로 운영하는것보다 훨씬 효율적인데, REST-API 
로 커넥트에 통신을 하여 반복적으로 만들 수 있다는 장점이 있다
```
* 커넥트(소스) : 
  * 프로듀서 역할 
  * 특정 데이터베이스나 소스 애플리케이션으로 부터  데이터를 가져와서 토픽에 넣는역할
* 커넥트(싱크) : 
  * 컨슈머 역할
  * 타겟 애플리케이션으로 데이터를 보내는 역할
___

## 카프카 브로커와 클러스터
`주키퍼` : 카프카 클러스터를 운영하기 위해 반드시 필요한 애플리케이션, 버전2까지는 필수이며 버전3부터는 주키퍼 없이 클러스터 운영이 가능하다(단, 아직 완벽하진 않음)
```
- 한개의 카프카 클러스터는 여러개의 브로커로 이루어져 있다
- 한개의 브로커는 한개의 Physical-Machine 이나 서버 혹은 Instance에서 동작하게 된다
- 상용환경에서 최소한 3개의 브로커를 운용하는게 일반적이고 데이터량이 많고 확장이 
 필요한 경우에는 50~100개까지 운영하는 경우도 있다
- 또는 상황에 따라서 클러스터를 2~3개로 나눠서 운영하는 경우도있다
```
`브로커` : 데이터를 분산저장하여 장애가 나더라도 데이터를 안전하게 사용할 수 있도록 도와주는 애플리케이션
___
## 카프카 클러스터와 주키퍼
`클러스터` : 
* 카프카 클러스터를 실행하기 위해서는 주키퍼가 필요함
* 여러대를 동시에 운영하는 경우도 많음(주키퍼 앙상블) 여러대를 운영하기 위해서는
* 주키퍼의 서로 다른 znode에 클러스터를 지정하면 되며, root znode에 <br>
각 클러스터별 znode를 생성하고 클러스터 실행시 root가 아닌 하위 znode로 설정
* 카프카3버전 부터는 주키퍼가 없어도 클러스터 동작 가능
___
## 브로커의 역할 - 컨트롤러, 데이터 삭제
`컨트롤러` :
* 다수의 브로커중 한대가 컨트롤러 역할을 한다
* 다른 브로커들의 상태체크, 브로커가 클러스터에서 빠지는 경우에(어떠한 이슈가 생겼을 경우) 브로커에 존재하는<br> 리더파티션을 재분배 한다
* 카프카는 지속적으로 데이터를 처리해야 하므로 비정상적인 브로커를 빠르게 클러스터에서 빼내는 것이 중요하다
* 컨트롤러 역할을 하는 브로커가 장애가 생기면 다른 브로커가 역할을 대신한다
```
데이터삭제:
- 다른 메시징 플랫폼과는 다르게 컨슈머가 데이터를 가져가도 토픽의 데이터는 삭제되지 않는다
- 데이터 삭제는 오직 브로커만 가능하며 파일 단위로 이루어지는데 이 단위를  '로그 세그먼트(log segment)'라고 한다
- 세그먼트에는 다수의 데이터가 들어있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다
- CleanUp Policy라고 하는 delete 옵션에 의해서 특정 시간, 용량에 따라서 삭제를 수행할 수 있고 혹은 특수한 상황에서 Compact 옵션을 주게되면 가장 최신의 메시지KEY 가 있는 레코드를 제외하고 나머지 메시지KEY 가 있는 레코드를 삭제 할 수도있다
```
`컨슈머의 오프셋 저장` :
* 컨슈머가 토픽에서 데이터를 가져가면 어느 위치까지 가져갔는지 commit을 하게되는데 이때 __consumer_offsets 토픽에 저장한다.
* __consumer_offsets 토픽은 자동으로 생성되어 자동으로 관리되기 때문에 Internal 토픽이라고 부른다

`그룹 코디네이커`:
* 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다
* 일반적으로 파티션과 컨슈머는 1:1 매칭되는데 특정 컨슈머에 문제가 생길경우 문제가 발생한 컨슈머와 매칭되어있던 파티션이 다른 문제없는 파티션을 바라보도록 재할당(`리밸런스(rebalance)`) 하여 데이터가 끊임없이 처리되도록 도와준다
___

## 브로커의 역할 - 데이터의 저장
* 카프카를 실행할 때 config/server.properties의 log.dir 옵션에 정의한 디렉토리에 데이터를 저장한다
* 토픽의 이름과 파티션 번호의 조합으로 디렉토리가 생성된다
  * 예시) 파티션이 3개라면 hello.kafka-0, hello.kafka-1, hello.kafka-2
* 그 하위에 .index, .log, .timeindex, leader-epoch-checkpoint 와 같이 로그와 관련된 데이터파일들이 생성된다
  * log에는 메시지와 메타데이터를 저장
  * index는 메시지의 오프셋을 인덱싱한 정보를 담는다
  * timeindex에는 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보가 담긴다
  
## 로그와 세그먼트
* 여기서 말하는 로그는 .log 라고하는 세그먼트 파일이다
* 로그는 저장 할 최대크기를 설정 할 수도 있고, 신규 생성 될 다음 파일로 넘어가는 시간 주기를 설정 할 수도있다
  * log.segment.bytes: 바이트 단위의 최대 세그먼트 크기 지정 (기본값은 1GB)
  * log.roll.ms(hours): 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기 (기본값은 7일)
* 가장 마지막 세그먼트 파일(쓰기가 일어나고 있는 파일)을 `액티브 세그먼트`라고 부른다
* 액티브 세그먼트는 브로커의 삭제대상에 포함되지 않는다
* 액티브가 아닌 일반 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다
___

## 세그먼트와 삭제 주기(cleanup.policy=delete)
* delete 옵션은 세그먼트 파일을 삭제할때 사용하는 옵션이다(active 제외)
  * retention.ms(minutes, hours): 세그먼트를 보유할 최대 기간(기본값 7일)
  * retention.bytes: 파티션당 로그 적재 바이트 값(기본값 -1, 지정하지 않음을 뜻함)
  * log.retention.check.interval.ms: 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격(기본값 5분)
## 세그먼트의 삭제
### (cleanup.policy=delete)
* 데이터삭제는 세그먼트 단위로만 이뤄지며 로그 단위(레코드 단위)로 개별삭제는 불가능하다
* 또한, 로그(레코드)의 메시지 키, 메시지 값, 오프셋, 헤더 등 이미 적재된 데이터의 수정또한 불가능 하기 때문에<br>프로듀서에서 데이터를 전송하기전, 컨슈머에서 데이터를 가져온 직후 데이터가 정상적인지 검증하는 과정이 필요하다
### (cleanup.policy=compact)
* 토픽 압축 정책은 일반적인 zip압축과는 다른 개념이다
* 하나의 세그먼트에는 동일한 메시지key를 여러 offset에 저장하는 경우가 생기는데 이때 최신 offset을 남겨두고 나머지 offset은 전부 삭제시키는 방식이다
* 물론 이 경우에도 active는 삭제대상에서 제외된다

### 테일/헤드 영역, 클린/더티 로그
* 테일 영역: 압축 정책에 의해 압축이 완료 된 레코드들, 중복 메시지 키가 없기 때문에 클린(clean)로그라고도 부른다
* 헤드 영역: 압축 정책이 되기 전 레코드들, 중복 메시지 키가 존재하기 때문에 더티(dirty)로그 라고도 부른다
* 데이터 압축 시작 시점 : min.cleanable.dirty.ratio 옵션을 따른다
  * 액티브 세그먼트를 제외한 세그먼트에 남아있는 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수의 비율을 뜻한다.
  * 0.5로 설정하면 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수가 동일할 경우 압축이 실행된다
  * 0.9와 같이 크게 설정하면 압축 시 데이터가 많이 줄어들기 때문에 압축효과가 좋으나 0.9비율이 될때까지 용량을 차지한다는 단점이 있다
  * 0.1과 같이 작게 설정하면 압축이 자주 일어나 가장 최신 데이터만 유지할 수 있지만 그만큼 브로커에 부담을 준다
___
## 브로커의 역할 - 복제(Replication)
* 복제를 통해 카프카는 장애허용 시스템(fault tolerant system)으로써 동작할 수 있다
* 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터 복제를 통해 데이터 유실을 방지한다
* 복제는 파티션 단위로 이뤄진다
* 토픽을 생성할때 파티션의 복제개수(replication factor)도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션을 따라간다
* 복제 개수의 최솟값은1(복제없음)이고 최댓값은 브로커 개수만큼 설정 가능하다
* 프로듀서에 의해서 데이터가 처음 저장되는 파티션을 리더 파티션, 복제가 이뤄지는 파티션을 팔로워 파티션 이라고한다, 참고로 컨슈머도 리더 파티션으로 부터 데이터를 가져간다
* replication factor 가 3이고 데이터가 1GB 들어왔다고 가정한다면 나머지 팔로워 파티션에도 각각 1GB가 저장되기 때문에 총 3GB가 저장된다(Disk를 소모하여 고가용성을 챙기는 행위)
* 일반적으로 factor 2를 사용하고 gps 정보와 같이 일부 데이터가 유실되어도 큰 영향이 없는 경우 1, 금융 정보와 같이 유실에 민감한 데이터의 경우 3을 설정한다
* factor 설정값이 커질수록 그만큼 네트워크 통신도 더 발생하고 디스크 소모도 배수로 늘어나는 것을 고려해야한다
___
## ISR(In-Sync-Replicas)
* ISR은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다
* 리더 파티션에 오프셋3까지 데이터가 저장되어있는데 팔로워 파티션에 오프셋2까지만 저장되어 있다면 싱크가 이뤄지지 않았다고 판단한다
* 싱크가 되지 않은 상태에서 팔로워 파티션을 새로운 리더로 선출할 경우가 필요할 수도 있다
(= 서비스를 중단하지 않고 지속적으로 토픽을 사용)
  * unclean.leader.election.enable=true : 유실을 감수함. 복제가 안된 팔로워 파티션을 리더로 승급
  * unclean.leader.election.enable=false : 유실을 감수하지 않음. 해당 브로커가 복구될 때까지 중단
### (ISR이 완전히 이뤄지지 않은 상태에서 컨슈머는 어디까지 데이터를 가져가는가?)
* 토픽에서 min.insync.replicas=2 와 같은 옵션을 설정할 수 있다
* 리터 파티션(오프셋3) / 팔로워 파티션1(오프셋2) / 팔로워 파티션2(오프셋1)의 상태일때 위 옵션에 따라서 오프셋2까지 데이터를 가져가게 되며 옵션값이3 이였다면 오프셋1까지 가져가게된다
* 컨슈머가 가져갈 수 있는 상태의 레코드 오프셋 번호를 하이 워터마크라고 부른다